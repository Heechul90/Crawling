html_nodes(css = '.type06_headline') %>%
html_nodes('a') %>%
html_attr('href'))
title <- html_text(node_1)
title <- html_name(node_1)
for(page_url in 1:10) {
url <- paste(base_url, page_url, sep='')
html <- read_html(url)
node_1 <- unique(html_nodes(html, '#main_content') %>%
html_nodes(css = '.list_body') %>%
html_nodes(css = '.type06_headline') %>%
html_nodes('a') %>%
html_attr('href'))
title <- html_name(node_1)
}
title <- html_attrs(node_1)
title <- html_text(node_1)
for(page_url in 1:10) {
url <- paste(base_url, page_url, sep='')
html <- read_html(url)
node_1 <- unique(html_nodes(html, '#main_content') %>%
html_nodes(css = '.list_body') %>%
html_nodes(css = '.type06_headline') %>%
html_nodes('a') %>%
html_attr('href'))
title <- html_text(node_1)
}
title
for(page_url in 1:5) {
url <- paste(base_url, page_url, sep='')
html <- read_html(url)
node_1 <- html_nodes(html, '.score_reple p')
node_2 <- html_nodes(html, '.star_score em')
reple <- html_text(node_1)
score <- html_text(node_2)
}
date <- 20190701:20190703
page <- 1:5
for(dt in date) {
for(page_num in page) {
url <- paste(base_url, dt, &page=, page_num, sep='')
}
}
for(dt in date) {
for(page_num in page) {
url <- paste(base_url, dt, '&page=', page_num, sep='')
}
}
# 링크 가져와서 찾아가기
base_url <- 'https://news.naver.com/main/list.nhn?mode=LS2D&sid2=228&mid=shm&sid1=105&date='
date <- 20190701:20190703
page <- 1:5
for(dt in date) {
for(page_num in page) {
url <- paste(base_url, dt, '&page=', page_num, sep='')
}
}
url
for(dt in date) {
for(page_num in page) {
url <- paste(base_url, dt, '&page=', page_num, sep='')
print(url)
}
}
## 인피니티워 네이버 평점 페이지 주소 ##
main_url = 'https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=136315&type=after&onlyActualPointYn=N&order=newest&page='
for(page_url in 1:10) {
url <- paste(main_url, page_url, sep='')
content <- read_html(url)
node_1 <- html_nodes(content, '.score_reple p')
}
node_1
for(page in 1:10) {
url <- paste0(main_url, page)
content <- read_html(url)
node_1 <- html_nodes(content, 'div.score_reple p')
}
for(page in 1:10) {
url <- paste0(main_url, page)
content <- read_html(url)
node_1 <- html_nodes(content, 'div.score_reple p')
print(node_1)
}
for(page in 1:10) {
url <- paste0(main_url, page)
content <- read_html(url)
node_1 <- html_nodes(content, 'div.score_reple p')
}
node_1
print(node_1)
for(page in 1:10) {
url <- paste0(main_url, page)
content <- read_html(url)
node_1 <- html_nodes(content, 'div.score_reple p')
print(node_1)
}
reple = c()
for(page in 1:10) {
url <- paste0(main_url, page)
content <- read_html(url)
node_1 <- html_nodes(content, 'div.score_reple p')
reple <- c(reple, node_1)
}
reple
news_url <- c()
new_date <- c()
news_date <- c()
# 링크 가져와서 찾아가기
base_url <- 'https://news.naver.com/main/list.nhn?mode=LS2D&sid2=228&mid=shm&sid1=105&date='
date <- 20190701:20190703
page <- 1:5
news_url <- c()
news_date <- c()
for(dt in date) {
for(page in page) {
url <- paste(base_url, dt, '&page=', page, sep='')
html <- read_html(url)
title <- html_nodes(html, '#main_content') %>%
html_nodes(css = '.list_body') %>%
html_nodes(css = '.type06_headline') %>%
html_nodes('a') %>%
html_attr(href)
news_url <- c(news_url, title)
news_date <- c(news_date, rep(dt,length(title)))
print(dt, page)
}
}
for(dt in date) {
for(page in page) {
url <- paste(base_url, dt, '&page=', page, sep='')
html <- read_html(url)
title <- html_nodes(html, '#main_content') %>%
html_nodes(css = '.list_body') %>%
html_nodes(css = '.type06_headline') %>%
html_nodes('a') %>%
html_attr('href')
news_url <- c(news_url, title)
news_date <- c(news_date, rep(dt,length(title)))
print(dt, page)
}
}
news_url
title <- read_html(base_url) %>%
html_nodes('#main_content') %>%
html_nodes(css = '.list_body') %>%
html_nodes(css = '.type06_headline') %>%
html_nodes('a') %>%
htma_attr(href)
news_date
title
title
for(dt in date) {
for(page in page) {
url <- paste(base_url, dt, '&page=', page, sep='')
html <- read_html(url)
title <- html_nodes(html, '#main_content') %>%
html_nodes(css = '.list_body') %>%
html_nodes(css = '.type06_headline') %>%
html_nodes('a') %>%
html_text('href')
news_url <- c(news_url, title)
news_date <- c(news_date, rep(dt,length(title)))
print(dt, page)
}
}
title
trim <- function (x) gsub("^\\s+|\\s+$", "", x)
for(dt in date) {
for(page in page) {
url <- paste(base_url, dt, '&page=', page, sep='')
html <- read_html(url)
title <- html_nodes(html, '#main_content') %>%
html_nodes(css = '.list_body') %>%
html_nodes(css = '.type06_headline') %>%
html_nodes('a') %>%
html_text('href')
title <- gsub("\\\\", "", title)
news_url <- c(news_url, title)
news_date <- c(news_date, rep(dt,length(title)))
print(dt, page)
}
}
title
for(dt in date) {
for(page in page) {
url <- paste(base_url, dt, '&page=', page, sep='')
html <- read_html(url)
title <- html_nodes(html, '#main_content') %>%
html_nodes(css = '.list_body') %>%
html_nodes(css = '.type06_headline') %>%
html_nodes('a') %>%
html_text('href')
title <- gsub("\\", "", title)
news_url <- c(news_url, title)
news_date <- c(news_date, rep(dt,length(title)))
print(dt, page)
}
}
title
for(dt in date) {
for(page in page) {
url <- paste(base_url, dt, '&page=', page, sep='')
html <- read_html(url)
title <- html_nodes(html, '#main_content') %>%
html_nodes(css = '.list_body') %>%
html_nodes(css = '.type06_headline') %>%
html_nodes('a') %>%
html_text('href')
title <- gsub("\\\\", "", title)
news_url <- c(news_url, title)
news_date <- c(news_date, rep(dt,length(title)))
print(dt, page)
}
}
title
for(dt in date) {
for(page in page) {
url <- paste(base_url, dt, '&page=', page, sep='')
html <- read_html(url)
title <- html_nodes(html, '#main_content') %>%
html_nodes(css = '.list_body') %>%
html_nodes(css = '.type06_headline') %>%
html_nodes('a') %>%
html_text('href')
title <- gsub("\\\\", "", title)
news_url <- c(news_url, title)
news_date <- c(news_date, rep(dt,length(title)))
print(title)
}
}
###.
base_url <- 'http://www.hanbit.co.kr/academy/books/category_list.html?page=1&cate_cd=004007&srt=p_pub_date'
html <- read_html(base_url)
book_list <- html_node(html, '.sub_book_list_area')
lis <- html_nodes(book_list, 'li')
lis
lis <- read_html(base_url) %>%
html_nodes('.sub_book_list_area') %>%
html_nodes('li')
lis
print(price)
print(price)
for(li in lis){
pr <- html_text(li, '.price') %>% html_text()
pr <- gsub('\\\\','', price)
price <- c(price, pr)
title <- c(title, html_nodes(li, '.book_tit') %>% html_text())
writer <- c(writer, html_nodes(li, '.book_writer') %>% html_text())
print(price)
}
## rvest의 동작순서서(text가져오기)
# 1) html 문서 데이터 가져오기
# 2) 필요한 노드 선택하기
# 3) 노드내에 text를 가져오기
lis <- read_html(base_url) %>%
html_nodes('.sub_book_list_area') %>%
html_nodes('li') %>%
html_text() %>%
data.frame()
###.
base_url <- 'http://www.hanbit.co.kr/academy/books/category_list.html?page=1&cate_cd=004007&srt=p_pub_date'
html <- read_html(base_url)
## rvest의 동작순서서(text가져오기)
# 1) html 문서 데이터 가져오기
# 2) 필요한 노드 선택하기
# 3) 노드내에 text를 가져오기
lis <- read_html(base_url) %>%
html_nodes('.sub_book_list_area') %>%
html_nodes('li')
lis
for(li in lis) {
price <- html_text(li, '.price')
price <- gsub('\\\\', '', price)
print(price)
}
for(li in lis){
pr <- html_text(li, '.price') %>% html_text()
pr <- gsub('\\\\','', price)
price <- c(price, pr)
title <- c(title, html_nodes(li, '.book_tit') %>% html_text())
writer <- c(writer, html_nodes(li, '.book_writer') %>% html_text())
print(price)
}
news_title <- c()
for(dt in date) {
for(page in page) {
url <- paste(base_url, dt, '&page=', page, sep='')
html <- read_html(url)
title <- html_nodes(html, '#main_content') %>%
html_nodes(css = '.list_body') %>%
html_nodes(css = '.type06_headline') %>%
html_nodes('a') %>%
html_text('href')
title <- gsub("\\\\", "", title)
news_title <- c(news_title, title)
news_url <- c(news_url, title)
news_date <- c(news_date, rep(dt,length(title)))
print(title)
}
}
# 링크 가져와서 찾아가기
base_url <- 'https://news.naver.com/main/list.nhn?mode=LS2D&sid2=228&mid=shm&sid1=105&date='
date <- 20190701:20190703
page <- 1:5
news_title <- c()
news_url <- c()
news_date <- c()
for(dt in date) {
for(page in page) {
url <- paste(base_url, dt, '&page=', page, sep='')
html <- read_html(url)
title <- html_nodes(html, '#main_content') %>%
html_nodes(css = '.list_body') %>%
html_nodes(css = '.type06_headline') %>%
html_nodes('a') %>%
html_text('href')
title <- gsub("\\\\", "", title)
news_title <- c(news_title, title)
news_url <- c(news_url, title)
news_date <- c(news_date, rep(dt,length(title)))
print(title)
}
}
for(dt in date) {
for(page in page) {
url <- paste(base_url, dt, '&page=', page, sep='')
html <- read_html(url)
title <- html_nodes(html, '#main_content') %>%
html_nodes(css = '.list_body') %>%
html_nodes(css = '.type06_headline') %>%
html_nodes('a') %>%
html_text('href')
title <- gsub("\\\\", "", title)
title <- c(title, title)
url <- c(url, title)
date <- c(date, rep(dt,length(title)))
print(title)
}
}
news <- data.frame(title=title, url=url, date=date)
for(dt in date) {
for(page in page) {
url <- paste(base_url, dt, '&page=', page, sep='')
html <- read_html(url)
title <- html_nodes(html, '#main_content') %>%
html_nodes(css = '.list_body') %>%
html_nodes(css = '.type06_headline') %>%
html_nodes('a') %>%
html_text('href')
title <- gsub("\\\\", "", title)
title <- c(title, title)
url <- c(url, title)
date <- c(date, rep(dt,length(title)))
print(title)
}
}
for(dt in date) {
for(page in page) {
url <- paste(base_url, dt, '&page=', page, sep='')
html <- read_html(url)
title <- html_nodes(html, '#main_content') %>%
html_nodes(css = '.list_body') %>%
html_nodes(css = '.type06_headline') %>%
html_nodes('a') %>%
html_text('href')
title <- gsub("\\\\", "", title)
title <- c(title, title)
print(title)
}
}
###. 필요 패키지
library(xlsx)
library(writexl)
library(curl)
library(httr)
library(rvest)
library(RSelenium)
library(dplyr)
library(stringr)
trim <- function (x) gsub("^\\s+|\\s+$", "", x)
# 링크 가져와서 찾아가기
base_url <- 'https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=143435&type=after&onlyActualPointYn=N&order=newest&page='
df_points <- data.frame(reple=c(), score=c(), date=c(), nickname=c())
for(page in 1 : 3)) {
url <- paste0(base_url,page)
content <- read_html(url)
node_1 <- html_nodes(content, '.score_reple p')
node_2 <- html_nodes(content, '.score_result .star_score em')
node_3 <- html_nodes(content, '.score_reple dt em:nth-child(2)')
node_4 <- html_nodes(content, '.score_reple dt em') %>%
html_nodes('a')
reple_list <- trim(html_text(node_1))
score_list <- trim(html_text(node_2))
date_list <- trim(html_text(node_3))
date_list <- gsub('\\.', '-', date_list)
nickname_list <- html_text(node_4, 'href')
nickname_list <- gsub("^\\s+|\\s+$", "", nickname_list)
one_df <- data.frame(reple=reple_list, score=score_list, date=date_list, nickname=nickname_list)
#print(score)
df_points <- rbind.data.frame(df_points, one_df)
}
for(page in 1 : 3) {
url <- paste0(base_url,page)
content <- read_html(url)
node_1 <- html_nodes(content, '.score_reple p')
node_2 <- html_nodes(content, '.score_result .star_score em')
node_3 <- html_nodes(content, '.score_reple dt em:nth-child(2)')
node_4 <- html_nodes(content, '.score_reple dt em') %>%
html_nodes('a')
reple_list <- trim(html_text(node_1))
score_list <- trim(html_text(node_2))
date_list <- trim(html_text(node_3))
date_list <- gsub('\\.', '-', date_list)
nickname_list <- html_text(node_4, 'href')
nickname_list <- gsub("^\\s+|\\s+$", "", nickname_list)
one_df <- data.frame(reple=reple_list, score=score_list, date=date_list, nickname=nickname_list)
#print(score)
df_points <- rbind.data.frame(df_points, one_df)
}
head(df_points)
write.xlsx(df_points,
col.names=TRUE,   # 변수이름을 그대로 사용
row.names=FALSE)  # 행이름은 사용하지 않음
write.xlsx('df_points.xlsx')
write.xlsx(df_points,
'review.xlsx')
write.xlsx(df_points,
'review.xlsx',
col.names=TRUE,   # 변수이름을 그대로 사용
row.names=FALSE)  # 행이름은 사용하지 않음
base_url <- 'https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=143435&type=after&onlyActualPointYn=N&order=newest&page='
df_points <- data.frame(reple=c(), score=c(), date=c(), nickname=c())
for(page in 1 : ceiling(18028/10)) {
url <- paste0(base_url,page)
content <- read_html(url)
node_1 <- html_nodes(content, '.score_reple p')
node_2 <- html_nodes(content, '.score_result .star_score em')
node_3 <- html_nodes(content, '.score_reple dt em:nth-child(2)')
node_4 <- html_nodes(content, '.score_reple dt em') %>%
html_nodes('a')
reple_list <- trim(html_text(node_1))
score_list <- trim(html_text(node_2))
date_list <- trim(html_text(node_3))
date_list <- gsub('\\.', '-', date_list)
nickname_list <- html_text(node_4, 'href')
nickname_list <- gsub("^\\s+|\\s+$", "", nickname_list)
one_df <- data.frame(reple=reple_list, score=score_list, date=date_list, nickname=nickname_list)
#print(score)
df_points <- rbind.data.frame(df_points, one_df)
}
###. 필요 패키지
library(xlsx)
library(writexl)
library(curl)
library(httr)
library(rvest)
library(RSelenium)
library(dplyr)
library(stringr)
trim <- function (x) gsub("^\\s+|\\s+$", "", x)
# 링크 가져와서 찾아가기
base_url <- 'https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=143435&type=after&onlyActualPointYn=N&order=newest&page='
df_points <- data.frame(reple=c(), score=c(), date=c(), nickname=c())
for(page in 1 : 3) {
url <- paste0(base_url,page)
content <- read_html(url)
node_1 <- html_nodes(content, '.score_reple p')
node_2 <- html_nodes(content, '.score_result .star_score em')
node_3 <- html_nodes(content, '.score_reple dt em:nth-child(2)')
node_4 <- html_nodes(content, '.score_reple dt em') %>%
html_nodes('a')
reple_list <- trim(html_text(node_1))
score_list <- trim(html_text(node_2))
date_list <- trim(html_text(node_3))
date_list <- gsub('\\.', '-', date_list)
nickname_list <- html_text(node_4, 'href')
nickname_list <- gsub("^\\s+|\\s+$", "", nickname_list)
one_df <- data.frame(reple=reple_list, score=score_list, date=date_list, nickname=nickname_list)
#print(score)
df_points <- rbind.data.frame(df_points, one_df)
}
head(df_points)
write.xlsx(df_points,
'review.xlsx',
col.names=TRUE,   # 변수이름을 그대로 사용
row.names=FALSE)  # 행이름은 사용하지 않음
ceiling(18028/10)
# 링크 가져와서 찾아가기
base_url <- 'https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=143435&type=after&onlyActualPointYn=N&order=newest&page='
df_points <- data.frame(reple=c(), score=c(), date=c(), nickname=c())
for(page in 1 : ceiling(18028/10)) {
url <- paste0(base_url,page)
content <- read_html(url)
node_1 <- html_nodes(content, '.score_reple p')
node_2 <- html_nodes(content, '.score_result .star_score em')
node_3 <- html_nodes(content, '.score_reple dt em:nth-child(2)')
node_4 <- html_nodes(content, '.score_reple dt em') %>%
html_nodes('a')
reple_list <- trim(html_text(node_1))
score_list <- trim(html_text(node_2))
date_list <- trim(html_text(node_3))
date_list <- gsub('\\.', '-', date_list)
nickname_list <- html_text(node_4, 'href')
nickname_list <- gsub("^\\s+|\\s+$", "", nickname_list)
one_df <- data.frame(reple=reple_list, score=score_list, date=date_list, nickname=nickname_list)
#print(score)
df_points <- rbind.data.frame(df_points, one_df)
}
write.xlsx(df_points,
'review.xlsx',
col.names=TRUE,   # 변수이름을 그대로 사용
row.names=FALSE)  # 행이름은 사용하지 않음
